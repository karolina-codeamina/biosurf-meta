{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTvx9MKMmjAL"
      },
      "outputs": [],
      "source": [
        "#preparing file for visualization & KEGG Reconstruct\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# input file to df, deleting comments, choosing lines\n",
        "\n",
        "df = pd.read_csv(\"found_ko_s_e10_p_e10_table.tsv\", sep=\"\\t\")\n",
        "df = df[[\"#query\", \"max_annot_lvl\", \"Description\", \"KEGG_ko\", \"KEGG_Pathway\"]]\n",
        "\n",
        "#explode KO column\n",
        "df[\"KEGG_ko\"] = df[\"KEGG_ko\"].str.split(\",\")\n",
        "df = df.explode(\"KEGG_ko\")\n",
        "#clean taxa column\n",
        "df[\"max_annot_lvl\"] = df[\"max_annot_lvl\"].str.split(\"|\").str[-1]\n",
        "#clean KO numbers\n",
        "df[\"KEGG_ko\"] = df[\"KEGG_ko\"].str.replace(\"ko:\", \"\", regex=True)\n",
        "#clean pathways lists\n",
        "df[\"KEGG_Pathway\"] = df[\"KEGG_Pathway\"].apply(lambda x: \",\".join([v for v in x.split(\",\") if v.startswith(\"ko\")]))\n",
        "df[\"KEGG_Pathway\"] = df[\"KEGG_Pathway\"].str.replace(\"ko\", \"\", regex=True)\n",
        "#filtering general pathways\n",
        "#(01100 - Metabolic pathways; 01110 - Biosynthesis of secondary metabolites; 01120 - Microbial metabolism in diverse environments) 01130?\n",
        "#to_remove = {\"ko01100\", \"ko01110\", \"ko01120\"}\n",
        "def remove_values(cell):\n",
        "    parts = cell.split(\",\")\n",
        "    filtered = [p for p in parts if p not in to_remove]\n",
        "    return \",\".join(filtered)\n",
        "#df[\"KEGG_Pathway\"] = df[\"KEGG_Pathway\"].apply(remove_values)\n",
        "#explode Pathways column\n",
        "df[\"KEGG_Pathway\"] = df[\"KEGG_Pathway\"].str.split(\",\")\n",
        "df = df.explode(\"KEGG_Pathway\")\n",
        "\n",
        "print(df)\n",
        "#3089 rows\n",
        "\n",
        "#to input file for kegg reconstruct\n",
        "df_kegg_input = df[[\"#query\", \"KEGG_ko\"]]\n",
        "df_kegg_input.to_csv(\"ko_kegg_input_table.tsv\", sep=\"\\t\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Intermediate step - KEGG Reconstruction\n",
        "Copy results from Pathways to file raw_kegg_reconstruct_results_ko_in_path_cat"
      ],
      "metadata": {
        "id": "dHQEpU-gmtN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#formatting KEGG_reconstruct results\n",
        "import re\n",
        "\n",
        "#open file copied from KEGG_reconstruct (pathways)\n",
        "with open(\"raw_kegg_reconstruct_results_ko_in_path_cat\", \"r\", encoding=\"utf-8\") as f:\n",
        "    content = f.read()\n",
        "kegg_reconstruct_to_tsv = \"ko_line\\tpath_id_line\\tpath_name_line\\tcategory_line\\tquery_line\\n\"\n",
        "ko_line = path_id_line = path_name_line = category_line = query_line = \"\"\n",
        "valid_change = 0\n",
        "#cleaning file format to tsv\n",
        "lines = content.split(\"\\n\")\n",
        "for line in lines:\n",
        "  if re.match(r\"^[0-9]{5}\", line):\n",
        "    parts = line.split(\" \")\n",
        "    path_id_line = parts[0]\n",
        "    path_name_line = \" \".join(parts[1:-1])\n",
        "  elif re.match(r\"^K[0-9]{5}\", line):\n",
        "    ko_line = line\n",
        "  elif re.match(r\"^query:\", line):\n",
        "    line = line.replace(\"query: \", \"\")\n",
        "    splitted_line = [x.strip() for x in line.split(\",\")]\n",
        "    queries = \", \".join(list(set(splitted_line)))\n",
        "    query_line = queries\n",
        "    valid_change = 1\n",
        "  elif re.match(r\"^[a-zA-Z]\", line):\n",
        "    category_line = line\n",
        "  else:\n",
        "    continue\n",
        "  if valid_change == 1:\n",
        "    kegg_reconstruct_to_tsv += f\"{ko_line}\\t{path_id_line}\\t{path_name_line}\\t{category_line}\\t{query_line}\\n\"\n",
        "    valid_change = 0\n",
        "  else:\n",
        "    continue\n",
        "\n",
        "print(kegg_reconstruct_to_tsv)\n",
        "#write to file\n",
        "with open(\"kegg_reconstruct_result.tsv\", \"w\") as f:\n",
        "    f.write(kegg_reconstruct_to_tsv)"
      ],
      "metadata": {
        "id": "6Aq1l2esmkmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mapping category & pathway names\n",
        "\n",
        "df_kegg_reconstruct_to_tsv = pd.read_csv(\"kegg_reconstruct_result.tsv\", sep=\"\\t\", dtype=str)\n",
        "df = df.astype(str)\n",
        "\n",
        "df_mapped = df.merge(\n",
        "    df_kegg_reconstruct_to_tsv,\n",
        "    left_on=[\"KEGG_ko\", \"KEGG_Pathway\"],\n",
        "    right_on=[\"ko_line\", \"path_id_line\"],\n",
        "    how=\"inner\",\n",
        ")\n",
        "df_mapped = df_mapped.drop(columns=[\"ko_line\", \"path_id_line\", \"query_line\"])\n",
        "df_mapped = df_mapped.sort_values(by='category_line')\n",
        "\n",
        "\n",
        "df_filtered = df_mapped[~df_mapped['category_line'].isin(['Nervous system', 'Neurodegenerative disease', 'Cardiovascular disease', 'Global and overview maps', 'Immune system', 'Cancer: overview', 'Cancer: specific types', 'Endocrine system', 'Circulatory system', 'Digestive system', 'Infectious disease: bacterial', 'Endocrine and metabolic disease', 'Aging' ])]\n",
        "df_mapped = df_filtered\n",
        "display(df_mapped)\n",
        "\n",
        "df_mapped.to_csv(\"table_for_alluvial_plot.tsv\", sep=\"\\t\", index=False)"
      ],
      "metadata": {
        "id": "DQqaljEmnUC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding Kraken2 Results"
      ],
      "metadata": {
        "id": "LFVerIvEnfks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#kraken2 to df\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "#reading report\n",
        "\n",
        "cols = [\"perc\", \"reads_clade\", \"reads_direct\", \"rank\", \"taxid\", \"name\"]\n",
        "df_kraken_report = pd.read_csv(\"kraken2.report\", sep=\"\\t\", names=cols)\n",
        "df_kraken_report[\"name\"] = df_kraken_report[\"name\"].str.strip()\n",
        "current_lineage = {\"D\": None, \"P\": None, \"C\": None, \"O\": None, \"F\": None, \"G\": None, \"S\": None}\n",
        "records = []\n",
        "\n",
        "for _, row in df_kraken_report.iterrows():\n",
        "    rank = row[\"rank\"]\n",
        "    if rank in current_lineage:\n",
        "        current_lineage[rank] = row[\"name\"]\n",
        "\n",
        "        # ‚Üê tutaj dodany fragment\n",
        "        reset = False\n",
        "        for r in [\"D\", \"P\", \"C\", \"O\", \"F\", \"G\", \"S\"]:\n",
        "            if reset:\n",
        "                current_lineage[r] = None\n",
        "            if r == rank:\n",
        "                reset = True\n",
        "\n",
        "    lineage_record = {\n",
        "        \"taxid\": row[\"taxid\"],\n",
        "        \"rank\": rank,\n",
        "        \"name\": row[\"name\"],\n",
        "        \"reads_clade\": row[\"reads_clade\"],\n",
        "        \"perc\": row[\"perc\"],\n",
        "        \"k2_domain\": current_lineage[\"D\"],\n",
        "        \"k2_phylum\": current_lineage[\"P\"],\n",
        "        \"k2_class\": current_lineage[\"C\"],\n",
        "        \"k2_order\": current_lineage[\"O\"],\n",
        "        \"k2_family\": current_lineage[\"F\"],\n",
        "        \"k2_genus\": current_lineage[\"G\"],\n",
        "        \"k2_species\": current_lineage[\"S\"],\n",
        "    }\n",
        "    records.append(lineage_record)\n",
        "\n",
        "\n",
        "species_df = pd.DataFrame(records)\n",
        "species_df = species_df.drop(columns=[\"rank\", \"reads_clade\", \"perc\"])\n",
        "\n",
        "#reading kraken2 clasification\n",
        "\n",
        "cols2 = [\"UC\", \"query\", \"taxo_name\", \"nr\", \"nr2\"]\n",
        "kraken2_clasif = pd.read_csv(\"kraken2_classification.tabular\", sep=\"\\t\", names=cols2)\n",
        "kraken2_clasif = kraken2_clasif.drop(columns=[\"nr\", \"nr2\"])\n",
        "kraken2_clasif = kraken2_clasif[kraken2_clasif[\"UC\"] == \"C\"]\n",
        "kraken2_clasif[\"taxid\"] = kraken2_clasif[\"taxo_name\"].str.extract(r\"\\((.*?)\\)\")\n",
        "kraken2_clasif[\"taxid\"] = kraken2_clasif[\"taxid\"].str.replace(r\"taxid \", \"\", regex=True)\n",
        "kraken2_clasif[\"taxo_name\"] = kraken2_clasif[\"taxo_name\"].str.replace(r\"\\s*\\(.*?\\)\", \"\", regex=True)\n",
        "kraken2_clasif[\"taxid\"] = pd.to_numeric(kraken2_clasif[\"taxid\"], errors=\"coerce\")\n",
        "\n",
        "print(kraken2_clasif)\n",
        "\n",
        "df_kraken = kraken2_clasif.merge(\n",
        "    species_df,\n",
        "    left_on=[\"taxid\"],\n",
        "    right_on=[\"taxid\"],\n",
        "    how=\"left\"\n",
        ")\n",
        "df_kraken = df_kraken.drop(columns=[\"taxo_name\", \"UC\"])\n",
        "\n",
        "df_kraken.to_csv(\"df_plot_with_kraken.tsv\", sep=\"\\t\", index=False)\n",
        "\n",
        "#adding eggnog info table with kegg reconstruct\n",
        "df_plot = pd.read_csv(\"table_for_alluvial_plot.tsv\", sep=\"\\t\")\n",
        "df_plot[\"#query\"] = df_plot[\"#query\"].str.split(\"_\").str[:-1].str.join(\"_\")\n",
        "\n",
        "\n",
        "df_mixed_with_kraken = df_plot.merge(\n",
        "    df_kraken,\n",
        "    left_on=\"#query\",\n",
        "    right_on=\"query\",\n",
        "    how=\"left\"\n",
        ")\n",
        "df_mixed_with_kraken = df_mixed_with_kraken.drop(columns=[\"#query\", \"max_annot_lvl\", \"name\"])\n",
        "df_mixed_with_kraken = df_mixed_with_kraken.fillna(\"Unclassified\")\n",
        "print(df_mixed_with_kraken)\n"
      ],
      "metadata": {
        "id": "ekslMeWQnh77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#variables for alluvial plot preparation\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "#Unclassified cleaning\n",
        "\n",
        "mask_col2 = df_mixed_with_kraken[\"k2_phylum\"] == \"Unclassified\"\n",
        "mask_col1 = df_mixed_with_kraken[\"k2_domain\"] != \"Unclassified\"\n",
        "mask = mask_col2 & mask_col1\n",
        "df_mixed_with_kraken.loc[mask, \"k2_phylum\"] = \"Unspecified \" + df_mixed_with_kraken.loc[mask, \"k2_domain\"]\n",
        "\n",
        "mask_col2 = df_mixed_with_kraken[\"k2_class\"] == \"Unclassified\"\n",
        "mask_col1 = df_mixed_with_kraken[\"k2_phylum\"] != \"Unclassified\"\n",
        "mask = mask_col2 & mask_col1\n",
        "df_mixed_with_kraken.loc[mask, \"k2_class\"] = df_mixed_with_kraken.loc[mask, \"k2_phylum\"]\n",
        "\n",
        "mask_col2 = df_mixed_with_kraken[\"k2_order\"] == \"Unclassified\"\n",
        "mask_col1 = df_mixed_with_kraken[\"k2_class\"] != \"Unclassified\"\n",
        "mask = mask_col2 & mask_col1\n",
        "df_mixed_with_kraken.loc[mask, \"k2_order\"] = df_mixed_with_kraken.loc[mask, \"k2_class\"]\n",
        "\n",
        "mask_col2 = df_mixed_with_kraken[\"k2_family\"] == \"Unclassified\"\n",
        "mask_col1 = df_mixed_with_kraken[\"k2_order\"] != \"Unclassified\"\n",
        "mask = mask_col2 & mask_col1\n",
        "df_mixed_with_kraken.loc[mask, \"k2_family\"] = df_mixed_with_kraken.loc[mask, \"k2_order\"]\n",
        "\n",
        "mask_col2 = df_mixed_with_kraken[\"k2_genus\"] == \"Unclassified\"\n",
        "mask_col1 = df_mixed_with_kraken[\"k2_family\"] != \"Unclassified\"\n",
        "mask = mask_col2 & mask_col1\n",
        "df_mixed_with_kraken.loc[mask, \"k2_genus\"] = df_mixed_with_kraken.loc[mask, \"k2_family\"]\n",
        "\n",
        "mask_col2 = df_mixed_with_kraken[\"k2_species\"] == \"Unclassified\"\n",
        "mask_col1 = df_mixed_with_kraken[\"k2_genus\"] != \"Unclassified\"\n",
        "mask = mask_col2 & mask_col1\n",
        "df_mixed_with_kraken.loc[mask, \"k2_species\"] = df_mixed_with_kraken.loc[mask, \"k2_genus\"]\n",
        "\n",
        "\n",
        "#orders\n",
        "tax_cols = [\"k2_domain\", \"k2_phylum\", \"k2_class\", \"k2_order\", \"k2_family\", \"k2_genus\", \"k2_species\"]\n",
        "df_tax_sorted = df_mixed_with_kraken.sort_values(by=tax_cols, ascending=False)\n",
        "\n",
        "D_order = df_tax_sorted[\"k2_domain\"].unique().tolist()\n",
        "P_order = df_tax_sorted[\"k2_phylum\"].unique().tolist()\n",
        "C_order = df_tax_sorted[\"k2_class\"].unique().tolist()\n",
        "O_order = df_tax_sorted[\"k2_order\"].unique().tolist()\n",
        "F_order = df_tax_sorted[\"k2_family\"].unique().tolist()\n",
        "G_order = df_tax_sorted[\"k2_genus\"].unique().tolist()\n",
        "S_order = df_tax_sorted[\"k2_species\"].unique().tolist()\n",
        "\n",
        "\n",
        "#path_order\n",
        "df_path_sorted = df_mixed_with_kraken.sort_values(by=['category_line', 'path_name_line'])\n",
        "cat_order = df_path_sorted[\"category_line\"].unique().tolist()\n",
        "path_order = df_path_sorted[\"path_name_line\"].unique().tolist()\n",
        "\n",
        "\n",
        "#color mapping\n",
        "\n",
        "phylum_list = [\n",
        "    'Thermodesulfobacteriota', 'Pseudomonadota', 'Myxococcota',\n",
        "    'Gemmatimonadota', 'Cyanobacteriota', 'Campylobacterota',\n",
        "    'Bacteroidota', 'Bacillota', 'Actinomycetota', 'Acidobacteriota',\n",
        "    'Thermoproteota', 'Nitrososphaerota'\n",
        "]\n",
        "\n",
        "color_list = ['#00ffff', '#fa8072', '#ff0000', '#ffff00', '#ffc0cb', '#800080',\n",
        " '#f0e68c', '#00ff00', '#ff00ff', '#0000ff', '#006400', '#40e0d0', ]\n",
        "\n",
        "coloring_dict = dict(zip(phylum_list, color_list))\n",
        "\n",
        "df_mixed_with_kraken[\"color\"] = df_mixed_with_kraken[\"k2_phylum\"].map(coloring_dict)\n",
        "df_mixed_with_kraken.loc[df_mixed_with_kraken[\"k2_domain\"] == \"Unclassified\", \"color\"] = \"#808080\"\n",
        "df_mixed_with_kraken.loc[df_mixed_with_kraken[\"k2_phylum\"] == \"Unspecified Bacteria\", \"color\"] = \"#d3d3d3\"\n",
        "df_mixed_with_kraken.loc[df_mixed_with_kraken[\"k2_domain\"] == \"Archaea\", \"color\"] = \"#ffd700\"\n",
        "#print(df_mixed_with_kraken)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0GMGemclrdgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dimensions for plot\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "\n",
        "dim_D = go.parcats.Dimension(\n",
        "    values=df_mixed_with_kraken['k2_domain'],\n",
        "    categoryorder='array',\n",
        "    categoryarray=D_order,\n",
        "    label='Domain',\n",
        ")\n",
        "dim_P = go.parcats.Dimension(\n",
        "    values=df_mixed_with_kraken['k2_phylum'],\n",
        "    categoryorder='array',\n",
        "    categoryarray=P_order,\n",
        "    label='Phylum'\n",
        ")\n",
        "dim_C = go.parcats.Dimension(\n",
        "    values=df_mixed_with_kraken['k2_class'],\n",
        "    categoryorder='array',\n",
        "    categoryarray=C_order,\n",
        "    label='Class'\n",
        ")\n",
        "dim_O = go.parcats.Dimension(\n",
        "    values=df_mixed_with_kraken['k2_order'],\n",
        "    categoryorder='array',\n",
        "    categoryarray=O_order,\n",
        "    label='Order'\n",
        ")\n",
        "dim_F = go.parcats.Dimension(\n",
        "    values=df_mixed_with_kraken['k2_family'],\n",
        "    categoryorder='array',\n",
        "    categoryarray=F_order,\n",
        "    label='Family'\n",
        ")\n",
        "dim_G = go.parcats.Dimension(\n",
        "    values=df_mixed_with_kraken['k2_genus'],\n",
        "    categoryorder='array',\n",
        "    categoryarray=G_order,\n",
        "    label='Genus'\n",
        ")\n",
        "dim_S = go.parcats.Dimension(\n",
        "    values=df_mixed_with_kraken['k2_species'],\n",
        "    categoryorder='array',\n",
        "    categoryarray=S_order,\n",
        "    label='Species'\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "dim_path = go.parcats.Dimension(\n",
        "    values=df_mixed_with_kraken['path_name_line'],\n",
        "    categoryorder='array',\n",
        "    categoryarray=path_order,\n",
        "    label='Pathway'\n",
        ")\n",
        "\n",
        "dim_cat = go.parcats.Dimension(\n",
        "    values=df_mixed_with_kraken['category_line'],\n",
        "    categoryorder='array',\n",
        "    categoryarray=cat_order,\n",
        "    label='Category'\n",
        ")"
      ],
      "metadata": {
        "id": "1r_oqYmExT_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Alluvial plot\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import pandas as pd\n",
        "\n",
        "df_mixed_with_kraken.to_csv(\"df_alluvial_plot.tsv\", sep=\"\\t\", index=False)\n",
        "\n",
        "\n",
        "fig = go.Figure(data = [go.Parcats(\n",
        "    dimensions=[dim_P, dim_C, dim_O, dim_F, dim_G, dim_path, dim_cat],\n",
        "    line=dict(\n",
        "        color=df_mixed_with_kraken[\"color\"],\n",
        "    ),\n",
        "    hoveron=\"color\"\n",
        "    )])\n",
        "\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Taxonomic contribution to biosurfactant metabolism within the soil microbiome\",\n",
        "    width=2000,\n",
        "    height=3600,\n",
        "    font=dict(size=12, family=\"Arial\"),\n",
        "    margin=dict(r=200)\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "#write to files\n",
        "fig.write_html(\"alluvial_results.html\")"
      ],
      "metadata": {
        "id": "XDSQv_ASneSM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
